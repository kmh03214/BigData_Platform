# pyspark Yarn log 제거
log4j.properties파일 Loglevel 수정 후에도 yarn log가 대량 출력되어 User가 print한 내용이 확인 되지 않는 문제점 개선.

## Job을 클러스터에 제출했을 때, yarn 로그를 제거하는 방법.

Spark job 제출시, --conf 옵션에 __spark.driver.extraJavaOptions=-Dlog4j.configuration=/usr/lib/spark/conf/log4j.properties__ 를 입력한다.  
신기하게도, /usr/lib/spark/conf/log4j.properties는 아무경로나 지정해줘도 됨. (원인파악 필요.)


아래 코드로 테스트 결과, yarn로그가 획기적으로 줄어듦을 확인 할 수 있다.
~~~python
from pyspark.sql import SparkSession
import time

log4j = sc._jvm.org.apache.log4j
log4j.LogManager.getRootLogger().setLevel(log4j.Level.ERROR)

spark = SparkSession.builder.getOrCreate()
spark.sparkContext.setLogLevel("ERROR")

sc.setLogLevel("ERROR")
print('hello')


import logging
logger = logging.getLogger()
spark.sparkContext.setLogLevel("DEBUG")
logger = logging.getLogger()
logger.info('you log message')

time.sleep(10)
prin('hello2')
~~~